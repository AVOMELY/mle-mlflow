{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id запуска: f77be0bc19054519bfd96576847f78bd\n"
     ]
    }
   ],
   "source": [
    "# делаем import необходимых библиотек\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# устанавливаем локальное хранилище для наших экспериментов\n",
    "# хранилище должно быть такое же, как и при запуске сервиса\n",
    "mlflow.set_tracking_uri('file:./mlflow_experiments_store')\n",
    "\n",
    "# получаем id эксеримента, который создаётся по умолчанию\n",
    "# эксперимент по умолчанию называется Default\n",
    "experiment_id = mlflow.get_experiment_by_name(\"Default\").experiment_id\n",
    "\n",
    "# залогируем тестовую метрику и артефакт\n",
    "with mlflow.start_run(run_name='Default', experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_metric(\"test_metric\", 0)\n",
    "    mlflow.log_artifact(\"test_artifact.txt\", \"test_artifact\")\n",
    "\n",
    "print(f\"Run id запуска: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": \"rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net\", \n",
    "    \"port\": \"6432\",\n",
    "    \"dbname\": \"playground_mle_20240215_be4e056539\",\n",
    "    \"user\": \"mle_20240215_be4e056539\",\n",
    "    \"password\": \"aa844862a5de4e13ab2320a557df41d7\",\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определим название таблицы, в которой хранятся наши данные.\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n",
    "# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаёт объект курсора для выполнения запросов к базе данных\n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # получает список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "# создаёт объект DataFrame из полученных данных и имён столбцов. \n",
    "# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\n",
    "df = pd.DataFrame(data, columns=columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте список названий колонок\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Откройте файл для записи\n",
    "with open(\"columns.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "    # Запишите названия колонок в файл, используя запятую в качестве разделителя\n",
    "    fio.write(\",\".join(column_names))\n",
    "\n",
    "counts_columns = [\n",
    "    \"type\", \"paperless_billing\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "    \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\",\n",
    "    \"multiple_lines\", \"target\"\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for col in counts_columns:\n",
    "        # посчитайте уникальные значения для колонок, где немного уникальных значений (переменная counts_columns)\n",
    "    column_stat = df[col].value_counts().to_dict()\n",
    "    column_stat = {f\"{col}_{key}\": value for key, value in column_stat.items()}\n",
    "\n",
    "# обновите словарь stats\n",
    "    stats.update(column_stat)\n",
    "\n",
    "stats[\"data_length\"] = df.shape[0]\n",
    "stats[\"monthly_charges_min\"] = df[\"monthly_charges\"].min()\n",
    "stats[\"monthly_charges_max\"] = df[\"monthly_charges\"].max()\n",
    "stats[\"monthly_charges_mean\"] = df[\"monthly_charges\"].mean()\n",
    "stats[\"monthly_charges_median\"] = df[\"monthly_charges\"].median()\n",
    "stats[\"total_charges_min\"] = df[\"total_charges\"].min()\n",
    "stats[\"total_charges_max\"] = df[\"total_charges\"].max()\n",
    "stats[\"total_charges_mean\"] = df[\"total_charges\"].mean()\n",
    "stats[\"total_charges_median\"] = df[\"total_charges\"].median()\n",
    "stats[\"unique_customers_number\"] = df[\"customer_id\"].nunique()\n",
    "stats[\"end_date_nan\"] = df[\"end_date\"].isna().sum()\n",
    "\n",
    "\n",
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_fio\"\n",
    "RUN_NAME = \"data_check\"\n",
    "\n",
    "experiment_id = mlflow.create_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=RUN_NAME) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_artifact(\"columns.txt\", \"dataframe\")\n",
    "    mlflow.log_artifact(\"users_churn.csv\", \"dataframe\")\n",
    "    mlflow.log_metrics(stats)\n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "\n",
    "assert run.info.status == \"FINISHED\"\n",
    "\n",
    "\n",
    "os.remove(\"columns.txt\")\n",
    "os.remove(\"users_churn.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfitted_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.fitted_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming you have your true labels (y_test) and predicted labels (y_pred)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m _, err1, _, err2 \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43my_test\u001b[49m, prediction, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m      7\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, probas)\n\u001b[1;32m      8\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, prediction)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "# Assuming you have your true labels (y_test) and predicted labels (y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "# Create metrics dictionary\n",
    "metrics = {\n",
    "    \"err1\": err1,\n",
    "    \"err2\": err2,\n",
    "    \"auc\": auc,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1,\n",
    "    \"logloss\": logloss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_project_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
